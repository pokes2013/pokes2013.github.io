

# Nginx日志如何分析

分析 Nginx 日志的核心是**提取关键指标**、**定位异常请求**、**挖掘访问规律**，一般分为 **日志格式确认**、**工具选择**、**常用分析场景** 三个步骤，以下是具体可落地的方法：

## 一、 先确认 Nginx 日志格式

Nginx 默认有两种日志：**访问日志（access.log）** 和 **错误日志（error.log）**，分析前要先明确日志格式，避免解析错误。

### 1. 访问日志格式

默认格式在 `nginx.conf` 或站点配置文件中定义，示例如下：

```nginx
log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
                  '$status $body_bytes_sent "$http_referer" '
                  '"$http_user_agent" "$http_x_forwarded_for"';

access_log  /var/log/nginx/access.log  main;
```

关键字段含义：

|字段|含义|
|---|---|
|`$remote_addr`|客户端 IP|
|`$remote_user`|客户端用户（一般为空）|
|`$time_local`|访问时间|
|`$request`|请求行（方法 + URL + 协议）|
|`$status`|HTTP 状态码|
|`$body_bytes_sent`|发送给客户端的字节数|
|`$http_referer`|来源页面（Referer）|
|`$http_user_agent`|客户端浏览器 / 爬虫标识|
|`$http_x_forwarded_for`|真实客户端 IP（代理场景）|

### 2. 错误日志格式

错误日志记录 Nginx 运行错误、请求处理异常，默认配置：

```nginx
error_log  /var/log/nginx/error.log  warn;
```

日志级别从低到高：`debug` > `info` > `notice` > `warn` > `error` > `crit` > `alert` > `emerg`，级别越高记录的内容越严重。

## 二、Nginx日志分析工具

根据需求选择工具，从 **命令行工具（快速排查）** 到 **专业分析平台（可视化监控）** 覆盖不同场景。

### 1. 命令行工具（Linux 运维必备，快速高效）

直接用 `grep`、`awk`、`sort`、`uniq` 等命令组合分析，无需额外安装。

#### （1）统计独立 IP 访问次数

```bash
awk '{print $1}' /var/log/nginx/access.log | sort | uniq -c | sort -nr | head -10
```

- `awk '{print $1}'`：提取第 1 列（客户端 IP）
- `sort | uniq -c`：去重并统计次数
- `sort -nr`：按次数降序排序
- `head -10`：取访问量前 10 的 IP

#### （2）统计 HTTP 状态码分布

```bash
awk '{print $9}' /var/log/nginx/access.log | sort | uniq -c | sort -nr
```

- `$9` 对应默认格式的 `$status` 字段，可快速定位 404（资源不存在）、500（服务器内部错误）等异常。

#### （3）查找访问最频繁的 URL

```bash
awk '{print $7}' /var/log/nginx/access.log | sort | uniq -c | sort -nr | head -10
```

- `$7` 对应默认格式的请求 URL，可发现热点接口或爬虫频繁访问的路径。

#### （4）筛选特定时间段的日志

```bash
grep "20/Oct/2024:10:00" /var/log/nginx/access.log  # 精确到分钟
grep "20/Oct/2024" /var/log/nginx/access.log        # 精确到日期
```

#### （5）分析错误日志中的严重错误

```bash
grep "error" /var/log/nginx/error.log  # 筛选error级别日志
grep "crit" /var/log/nginx/error.log   # 筛选严重错误
```

### 2. 专业分析工具（可视化、长期监控）

适合生产环境的持续分析，支持图表展示、告警等功能。

|工具|特点|适用场景|
|---|---|---|
|**ELK Stack（Elasticsearch+Logstash+Kibana）**|开源日志分析标杆，支持海量日志存储、全文检索、可视化仪表盘|中大型企业、高并发场景|
|**Grafana + Loki + Promtail**|轻量级日志监控方案，与监控系统无缝集成，资源占用低|云原生环境、小型团队|
|**GoAccess**|命令行 / 网页版可视化工具，实时生成 HTML 报告，无需依赖数据库|快速生成可视化报告、临时分析|
|**AWStats**|专注 Web 日志分析，支持访客统计、搜索引擎分析|个人站点、小型网站|

#### GoAccess 快速使用示例（生成可视化报告）

```bash
# 安装（以CentOS为例）
yum install goaccess -y

# 实时生成HTML报告
goaccess /var/log/nginx/access.log -o /usr/share/nginx/html/report.html --log-format=COMBINED --real-time-html
```

访问 `http://服务器IP/report.html` 即可查看实时访问统计图表。

## 三、 常见分析场景与实战案例

### 1. 定位异常请求

- **场景 1**：发现大量 404 状态码，排查无效请求
  
    ```bash
    grep " 404 " /var/log/nginx/access.log | awk '{print $7}' | sort | uniq -c | sort -nr
    ```
    
    输出结果可看到哪些 URL 频繁返回 404，判断是用户输入错误还是资源被删除。
    
- **场景 2**：定位 500 错误的请求，排查服务故障
  
    ```bash
    grep " 500 " /var/log/nginx/access.log | head -10
    ```
    
    查看对应的请求 URL 和客户端 IP，结合后端服务日志（如 PHP、Java 日志）定位问题。
    

### 2. 识别爬虫与恶意访问

- **场景 1**：筛选爬虫请求（根据 User-Agent）
  
    ```bash
    grep -E "Baiduspider|Googlebot|360Spider" /var/log/nginx/access.log
    ```
    
- **场景 2**：发现单个 IP 高频访问，疑似攻击
  
    ```bash
    awk '{print $1}' /var/log/nginx/access.log | sort | uniq -c | sort -nr | head -5
    ```
    
    若某 IP 访问次数远超正常范围，可通过 Nginx 限制该 IP 访问：
    
    ```nginx
    deny 192.168.1.100;
    ```
    

### 3. 分析用户访问行为

- 统计不同时段的访问量，判断高峰时段：
  
    ```bash
    awk '{print substr($4,2,11)}' /var/log/nginx/access.log | sort | uniq -c | sort -nr
    ```
    
    输出结果如 `1000 20/Oct/2024`，可了解网站的访问高峰日期。

## 四、 注意事项

1. **日志切割**：Nginx日志会持续增大，需配置 `logrotate` 定期切割，避免单个日志文件过大无法分析。
2. **自定义日志格式**：默认格式可能不满足需求，可添加 `$request_time`（请求处理时间）、`$upstream_response_time`（后端响应时间）等字段，便于分析性能瓶颈。
3. **隐私保护**：分析日志时注意脱敏用户 IP 等敏感信息，避免合规风险。

---

我可以帮你整理一份**Nginx 日志分析常用命令清单**，方便你日常排查时直接复制使用，需要吗？